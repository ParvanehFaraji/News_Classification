{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   10000 non-null  object\n",
      " 1   text    10000 non-null  object\n",
      " 2   lebel   10000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n",
      "      title   text  lebel\n",
      "0     False  False  False\n",
      "1     False  False  False\n",
      "2     False  False  False\n",
      "3     False  False  False\n",
      "4     False  False  False\n",
      "...     ...    ...    ...\n",
      "9995  False  False  False\n",
      "9996  False  False  False\n",
      "9997  False  False  False\n",
      "9998  False  False  False\n",
      "9999  False  False  False\n",
      "\n",
      "[10000 rows x 3 columns]\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.9810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       995\n",
      "           1       0.98      0.99      0.98      1005\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Accuracy: 0.9885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       995\n",
      "           1       0.99      0.99      0.99      1005\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.9910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       995\n",
      "           1       0.99      0.99      0.99      1005\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.9920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       995\n",
      "           1       0.99      0.99      0.99      1005\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.9215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       995\n",
      "           1       0.92      0.92      0.92      1005\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.92      0.92      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n",
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "data = pd.read_csv('final_en.csv')\n",
    "data.describe()\n",
    "data.info()\n",
    "data.describe()\n",
    "result = data.isna()\n",
    "print(result)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "#Text Preproccessing \n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english') # remove \"the\", \"is\", \"in\", \"and\", \"of\", \"on\", \"a\", \"to\", \"with\", etc.\n",
    "X = tfidf.fit_transform(data['cleaned_text']).toarray()\n",
    "y = data['lebel']\n",
    "#Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#Train Multiple Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "model_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_predictions[name] = y_pred\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    " #Compare Results\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
    "results_df.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y=results_df['Accuracy'], palette='viridis')\n",
    "plt.title('Model Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
